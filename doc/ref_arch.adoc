:data-uri:
:rhtlink: link:https://www.redhat.com[Red Hat]
:mwlaboverviewsetup: link:http://people.redhat.com/jbride/labsCommon/setup.html[Middleware Lab Overview and Set-up]
:brmsproduct: link:https://access.redhat.com/documentation/en-US/Red_Hat_JBoss_BRMS/[Red Hat JBoss BRMS 6 product]
:datagridproduct: link:https://access.redhat.com/documentation/en-US/Red_Hat_JBoss_Data_Grid/[Red Hat JBoss Data Grid product]
:eapproduct: link:https://access.redhat.com/documentation/en-US/JBoss_Enterprise_Application_Platform/[JBoss Enterprise Application Platform product]
:haceppreso: link:http://www.slideshare.net/DuncanDoyle/doyle-h-0945highavailablitycepwithredhatjbossbrms3[High Available Complex Event Processing presentation]
:hacepgitrepo: link:https://github.com/DuncanDoyle/RHSummit2014HaCepBrms[source code]

= Highly Available JBoss BRMS CEP

*Goal*
Configure a highly available JBoss BRMS CEP deployment topology

:numbered:

== Overview
This document proposes a solution of high availability for CEP engines and address some challenges when combining JBoss BRMS CEP with HA, like the following:

* Session for CEP are:
** Stateful, state must be persisted.
** Used by all Events, sessions are not partitioned by event type, user or session-id.
** Memory consumption, sessions can have days, due to the events correlation behavior.

== Credits
This project builds upon the outstanding contributions of Dunkin Doyle and the Red Hat BRMS engineering team.

In particular, Dunkin's {haceppreso} and {hacepgitrepo} have been highly leveraged.

== Pre-Requisites

The remainder of this documentation provides instructions for installation, configuration and execution of this reference architecture in Red Hat's Partner Demo System.
The following is a list of pre-requisites:

. OPENTLC-SSO credentials
+
`OPENTLC-SSO` user credentials are used to log into the Red Hat Partner Demo System (PDS).
If you do not currently have an `OPENTLC-SSO` userId, please email: `OPEN-program@redhat.com`.

. Familiarity with Partner Demo System
+
If you are not already familiar with Red Hat's `Partner Demo System`, please execute what is detailed in the {mwlaboverviewsetup} guide.
Doing so will ensure that you are proficient with the tooling and workflow needed to complete this reference architecture in an OpenShift Platform as a Service environment.

. Familiarity with {brmsproduct}
. Complex Event Processing
. Familiarity with {datagridproduct}
. Familiarity with {eapproduct}

== Architecture Components

=== UML Deployment Diagram

=== Data Model

===  Messaging Broker

====  Purpose
====  Hornetq vs Apache Kafka discussion
====  HA Hornetq


=== Event UUID Object

=== BPMS/CEP Nodes
==== JMS Topic Consumer
==== Psuedo Clock
==== Event Processing
**  cep nodes receive JMS message. JMS message contains a CEP event.
** CEP clock is advanced
** rule engine is fired
** create the command in the RHS
** add that to cache.

==== Hot-Rod client

=== JBoss Data Grid
==== Purpose
Purpose of JDG is to store the commands generated in the RHS to have idempotent behaviour when the engine restarts.
It's used to implement the replay executions.

==== JDG Library Mode Deployment Topology
==== JDG Replication Mode State Transfer

=== Command Object
Need to be identical so as to prevent duplicate commands.
Command ID is composed of:   rule package, rule name and event uuid

=== Command Dispatcher

=== Command Executor

In a case of recovery commands in the cache would be read again but discarded since they already are in the cache. This can be better checked by just checking the last ID in the cache and the ID from the durable topic which have been read again in the recovery process so no need to check all of them and discard.

== Procedure
* For the purposes of this documentation, the name _$REF_ARCH_HOME_ refers to the root directory of this reference architecture.

=== Creation of 2 instances of EAP6 in OSE + datagrid (they should be in cluster)
=== Configure security, jms topic and roles.
=== Configure producer to run in local student machine (build process)
=== When a node crashes it replay all commands until it gets updated.

So a good list of steps would be:

* Overview
* Provision EAP instances
* EAP verification
* Configuration and Execution
** Local: Clone this reference architecture
** Local: Build the Reference Architecture
** Deploy the CEP application
** Configure datagrid (check the avaiability of cluster between gears)
** Configure HornetQ subsystem
* Test Details

== Steps to Reproduce the Environment

NOTE: The steps listed below are just to reproduce the environment with the solution working. Steps need to be polished and migrated to be OSE compliant.

Your system needs to be multi-homed. The provided startup scripts bind JBoss EAP to address 127.0.0.1, the CEP node 1 to 127.0.0.3 and the CEP node 2 to 127.0.0.4.

* Download this https://dl.dropboxusercontent.com/u/7034677/RHSummit2014HaCepBrms.zip[zip file] and unzip it.
* Change the path to your proper home directory (could be used `${user.home}`) in line 130 at `RHSummit2014HaCepBrms/RHSummitHaCepApp/pom.xml`
* Change the path to your proper home directory (could be used `${user.home}`) in line 69 at `RHSummit2014HaCepBrms/RHSummitHaCepEventProducer/pom.xml`
* Change the path to your proper home directory (could be used `${user.home}`) in line 14 at RHSummit2014HaCepBrms/RHSummitHaCepEventProducer/src/main/resources/logback.xml`
* Run `mvn clean install` on the root POM. The dependencies which were missing I fixed in this version.
* Download the `jboss-eap-6.3.0.zip` and `jboss-eap-6.3.3-patch.zip` from the *Red Hat Customer Support Portal* and place them in the `demo/installation_zips` directory.
* In the `demo` directory, run the `buildJBossEap-HaCepBrms-Demo-Environment.sh` script. This will setup JBoss EAP 6.3.3 in the `demo/target` directory.

NOTE: This last step will fail trying to connect the controller, but it will create the admin user/password and guest user/password. I solved doing all the steps manually as follows.

* After the execution of the `buildJBossEap-HaCepBrms-Demo-Environment.sh` script, run the `startJBossEAP.sh` script to start JBoss EAP. Open a new terminal move to `RHSummit2014HaCepBrms/demo/target/jboss-eap-6.3/bin`and connect to the controller manually by executing `./jboss-cli.sh -c`.
* In the prompt `[standalone@localhost:9999 /]` apply the patch by executing `patch apply /path/to/project/RHSummit2014HaCepBrms/demo/installation_zips/jboss-eap-6.3.3-patch.zip`. The return should be:

[source,json]
----
{
    "outcome" : "success",
    "response-headers" : {
        "operation-requires-restart" : true,
        "process-state" : "restart-required"
    }
}
----

* Now execute the command to create the Durable Topic:

-----
/subsystem=messaging/hornetq-server=default/jms-topic=EventTopic:add(entries=["topic/event", "java:jboss/exported/topic/event"])
-----

The return should be:

[source,json]
-----
{"outcome" => "success"}
-----

* The `guest` role must have the right permissions, so execute:

-----
/subsystem=messaging/hornetq-server=default/security-setting=#/role=guest:write-attribute(name=create-durable-queue, value=true)
-----

And then:

-----
/subsystem=messaging/hornetq-server=default/security-setting=#/role=guest:write-attribute(name=delete-durable-queue, value=true)
-----

* In the `demo/bin` directory, run the `startNodeOne.sh` and `startNodeTwo.sh` scripts to start the 2 CEP engines. Notice that the 2 engines create an Infinispan cluster.
* In the `demo/bin` directory, run the `startEventProducer.sh` script to start the EventProducer. This will send the events to the HornetQ system, from where they will be picked up by the CEP engines.
* To test the replay behavior stop one of the CEP engines and start it again. The commands will be replied but not executed, all of them must be discarded.

== Performance Testing
* JMeter is used to drive testing of the reference architecture.
* You do not need to download a seperate JMeter binary nor source distribution
* Instead, JMeter will be downloaded, installed and appropriately configured as part of the configuration found in $REF_ARCH_HOME/loadtest
* jmeter maven plugin
** Notice use of the com.lazerycode.jmeter:jmeter-maven-plugin in _$REF_ARCH_HOME/loadtest/pom.xml_
** This maven plugin downloads, installs and appropriately configures JMeter
** This maven plugin is also used to drive test scenarios
* ref_arch.jmx
** A sample default jmeter load test definition file is included in: $REF_ARCH_HOME/loadtest/src/test/jmeter/ref_arch.jmx
** This jmeter load test definition file can be viewed and manipulated via the JMeter GUI by:
*** cd $REF_ARCH_HOME/loadtest
** Notice that the default, OOB configuration is to spawn a single client that invokes a single test case
** ./jmeter_gui.sh
* Java Sampler
** Also included is an example Java _Sampler_ at:  $REF_ARCH_HOME/loadtest/src/test/java/com/redhat/gpe/refarch/ref_arch_template/loadtest/ExampleJMeterClient.java
** The use of a JMeter _sampler_ class is optional
** cd $REF_ARCH_HOME/loadtest
** mvn clean verify

== To-Do
